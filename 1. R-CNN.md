# R-CNN

### R-CNN모델의 전반적인 흐름
<img src="https://user-images.githubusercontent.com/33839093/109092894-c02f0100-775a-11eb-85dc-0bff288aa64e.png" width="700">

1) 입력 이미지에 selective search 알고리즘을 적용해 물체가 있을만한 박스 2천개를 추출
2) 모든 박스를 227x227 크기로 resize, 박스의 비율은 고려하지 않음
3) pre-trained CNN에 통과시켜 4096차원의 특징 벡터를 추출
4) 추출된 벡터로 각각의 클래스(object의 종류)마다 학습시켜 놓은 SVM classifier를 통과시킴
5) bounding box regression을 적용해 bbox의 위치를 조정

### R-CNN은 2-stage detector
<img src="https://user-images.githubusercontent.com/33839093/109093326-84e10200-775b-11eb-9473-f0059145c0f8.png" width="700">

> 물체의 위치를 찾는 **region proposal**
물체를 분류하는 **region classification**

### 1. Region Proposal : 주어진 이미지에서 물체가 있을만한 위치 찾기

- **Sliding Window**
<img src="https://user-images.githubusercontent.com/33839093/109094131-d8078480-775c-11eb-9ba7-5e11230f1f30.png" width="700">

> 이미지에서 물체를 찾기 위해 window의 크기와 비율을 임의로 바꿔가면서 모든 영역을 탐색하는 방법

- **Selective search**
<img src="https://user-images.githubusercontent.com/33839093/109094139-da69de80-775c-11eb-99c0-114359c7ef71.png" width="700">

> - 색상, 질감, 영역의 크기 등을 이용해 non-object-based segmentation을 수행 (이 작업을 통해 제일 아래 그림처럼 많은 small segmented areas를 얻음)
> - bottom-up방식으로 small segmented areas를 합쳐서 더 큰 segmented ared를 만듦  
> - 두 번째 단계를 반복해 총 2000개의 region proposal을 생성

👉 이 과정은 매우 많은 시간이 걸려 요즘은 region proposal과정을 뉴럴 네트워크가 수행함

### 2. Feature Extraction/CNN
> - Selective search로 찾은 2천개의 박스 -> 227x227크기로 resize(warp) : CNN의 fc layer에 넣기 위해서는 이미지 사이즈가 모두 동일해야 하기 때문 -> pretrained된 CNN모델을 통과시켜 4096크기의 특징 벡터를 추출
> - Caffe CNN library를 ILSVRC2012 classification데이터로 pre-trained시킨 후, 논문에서 사용할 데이터셋에 맞게 fine-tuning함 (http://caffe.berkeleyvision.org/)

👉 Imagenet으로 학습된 CNN을 가져와, object detection용 데이터셋으로 fine-tuning한 뒤, selective search결과로 뽑힌 이미지들에서 특징 벡터를 추출함

### 3. Classification
> - CNN을 통해 추출한 특징벡터로 각각 클래스별로 SVM classifier를 학습시킴 (주어진 벡터가 해당 클래스인지 아닌지를 구분하는 classifier)
> - 왜 classificer로 softmax를 사용하지 않고 SVM을 사용했을까?
CNN fine-tuning을 위한 학습 데이터가 많지 안아 softmax를 적용하면 오히려 성능이 낮아져 본 논문에서는 SVM을 사용함
> - 특징벡터를 추출한 뒤 SVM classifier를 붙여 학습하는 기법은 요즘 사용되지 않음

### 4. Non-Maximum Suppression
> - SVM을 통과하면 각각의 박스들은 어떤 물체일 확률 값(score)을 가짐
> - Non-Maximum Suppression : 동일한 물체에 박스가 여러개 쳐저 있으면 가장 score가 높은 박스만 남기고 나머지는 제거

👉 서로 다른 박스가 동일한 물체에 쳐져 있는지 판별하기 위해서 iou(intersection over union)개념이 사용됨 : 두 박스의 교집합을 합집합으로 나눠준 값

<img src="https://user-images.githubusercontent.com/33839093/109096109-48fc6b80-7760-11eb-8020-67f10af5ed8a.png" width="600">

> - 두 박스가 일치할수록 1에 가까운 값을 가짐
> - 본 논문에서는 iou값이 0.5보다 크면 동일한 물체를 대상으로 한 박스라 판단함


 ### 5. Bounding Box Regression
- Selective search를 통해서 찾은 박스의 위치는 정확하지 않기 때문에, bounding box regression을 적용함(박스의 위치를 조정해 성능을 높이기 위해서)
- 물체가 어떤 클래스에 속하는지 찾는게 아니라, bbox를 잘 찾는 과정

![rcnn_eq1](https://user-images.githubusercontent.com/33839093/109096629-3fbfce80-7761-11eb-98aa-d51faf92b461.JPG)
> - P : selective search로 찾은 박스
> - G : ground truth 박스
> - x, y, w, h : 이미지의 중심좌표, 너비, 높이

<img src="https://user-images.githubusercontent.com/33839093/109096591-2c146800-7761-11eb-9590-831f6adef93e.png" width="700">

> - G hat 수식(1), (2), (3), (4): P를 G로 이동시키는 함수
> - 수식(6), (7), (8), (9): 수식(1), (2), (3), (4)에서 G hat을 G로 바꾸고, d를 t로 치환해 t에 대해 정리한 것
> - 수식(5): loss function으로, d와 t의 차이인 loss를 줄여나가는 방향으로 학습 (람다=1000)

<img src="https://user-images.githubusercontent.com/33839093/109096593-2dde2b80-7761-11eb-957b-b550eea16c4a.png" width="300">

> - d: 우리가 학습을 통해 얻고자 하는 함수
> - d함수를 구하기 위해서 2번 CNN을 통과시킬 때 pool5 레이어에서 얻어낸 특징 벡터를 사용함
> - d함수에 학습 가능한 weight vector를 주어 계산함

👉 CNN을 통과해 추출된 벡터와 x, y, w, h를 조정하는 함수의 weight를 곱해서 bounding box를 조정해주는 선형 회귀를 학습시킴

### R-CNN에서 학습이 일어나는 부분
	- 이미지넷으로 이미 학습된 모델을 가져와 fine-tuning하는 부분
	- SVM classifier를 학습시키는 부분
	- Bounding box regression

### R-CNN의 단점
	- 오래 걸린다: selective search로 뽑아낸 2000개의 이미지에 모두 CNN을 수행하기 때문
	- 복잡한 구조: CNN, SVM, Bounding Box Regression까지 총 3가지 모델을 필요로 함
  - Back Propagation이 안됨: SVM, Bounding Box Regression에서 학습한 결과라 CNN을 업데이트 시키지 못함
