# YOLO v1

<img src="https://user-images.githubusercontent.com/33839093/109772187-0f849e00-7c41-11eb-8cbb-149cde9dc44c.png" width="600">

→ YOLO는 Faster R-CNN과 비교했을 때 정확도는 조금 떨어지지만, 속도가 6배 정도 빠름 (fps는 속도, mAP는 정확도)

### Unified Detection

- 기존의 object detection : region proposal과 classification 두 단계로 나누어서 진행
- YOLO : region proposal없이 한번에 object detection을 수행
> 1) 이미지를 SxS 크기의 그리드 영역으로 나눔 (실제 입력 이미지를 나누는 것X)
> 2) 각 그리드 영역에서 물체가 있을만한 영역에 B개의 bounding box를 예측
> - bounding box는 (x, y, w, h)로 나타냄
> - (x, y)는 bbox의 중심점 좌표이고, w, h는 너비와 높이
> 3) 해당 박스의 신뢰도를 나타내는 confidence를 계산
> - confidence는 ①해당 그리드에 물체가 있을 확률 Pr(Object), ②예측한 박스와 Ground Truth 박스와의 겹치는 영역의 비율인 IoU를 곱해서 계산 (①×②)

### Network Design
<img src="https://user-images.githubusercontent.com/33839093/109773338-6dfe4c00-7c42-11eb-964d-5663b2a3f763.JPG" width="700">

> - 7x7x30 feature map에 대해 알아보면:
> - 7x7은 그리드를 의미, 각각의 인덱스는 30차원의 벡터 값을 가짐
> - 하나의 인덱스(빨간 박스)에 대해서 B개의 bbox를 추측(논문에서는 B=2로 설정)
> - 30차원의 벡터 중, 앞의 10개는 노란 bbox 2개를 의미함
> 👉 bbox 1개는 중심점(x, y), 너비와 높이(w, h), 신뢰도 지수(C)로 (x, y, w, h, C) 5차원 벡터로 표현됨
