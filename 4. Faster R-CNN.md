# Faster R-CNN

    - Fast R-CNN에서는 selective search를 사용한 후 ROI pooling(stride를 다르게 max pooling 적용)을 통해 fc layer에 넣기 전 feature vector의 크기를 맞춰줌
    - Faster R-CNN에서는 이 과정을 RPN으로 대체함
    - 핵심 아이디어:
    - Fast R-CNN에서 selective search가 했던 일을 Region Proposal Network(RPN)가 대신함 → GPU로 ROI계산 가능, 연산량 감소
    - 진정한 의미의 end-to-end object detection 모델을 제시

	- 위 : 기존 CNN모델의 알고리즘
	- 아래 : 제안하는 SPPnet의 알고리즘


### 전체 알고리즘
<img src="https://user-images.githubusercontent.com/33839093/109638891-e527d780-7b91-11eb-9237-581a036505a3.png" width="500">

👉 입력 이미지 → CNN(feature map 추출) → RPN에 전달해 ROI계산 → ROI pooling → classification & bbox regression 수행

### RPN(Region Proposal Network)
<img src="https://user-images.githubusercontent.com/33839093/109639004-04266980-7b92-11eb-9fdb-c01202f9d6a2.png" width="500">

- pretrained CNN을 거쳐 나온 feature map은 ZFNet & 256-d VGG-16을 기준으로 512-d을 가짐
- feature map은 k개의 anchor box를 통해 영역을 정하고, classification layer와 bounding box regression을 거쳐 물체가 있는 곳을 학습함
- classification layer는 물체가 있는지/없는지만 확인하기 때문에 2개의 클래스를 가짐
(많은 Faster R-CNN 코드들이 VGG-16모델을 backbone으로 사용함)

1) anchor targeting
<img src="https://user-images.githubusercontent.com/33839093/109639318-62534c80-7b92-11eb-95fe-2820c8ad61d6.png" width="300">

> - 3개의 scale과 3개의 ratio를 사용해 9개의 anchor box를 만듦
> - 50x50 feature map의 각 중심점 기준으로 9개의 anchor box를 만듦

<img src="https://user-images.githubusercontent.com/33839093/109639865-10f78d00-7b93-11eb-88cb-c7b007424ed1.jpg" width="700">

> - 1을 labeling한 경우 : iou가 가장 큰 anchor와 iou가 0.7보다 큰 anchor
> - label이 0, 1이 아닌 anchor는 학습에 사용되지 않음


2) prediction
<img src="https://user-images.githubusercontent.com/33839093/109640190-7a779b80-7b93-11eb-9191-53b3b3b6e3ec.jpg" width="700">

> - fully-connected layer 대신 convolutional layer를 사용 : 입력 이미지 크기에 상관없이 연산을 하기 위해서
> - classification layer에는 해당 anchor가 물체를 포함하는지 확률 값을 얻음
> - bbox regression layer에서는 좌표를 얻음
> - 👉 2)에서 prediction한 결과로 1)에서 구한 ground truth label과 함께 loss function을 통해 RPN을 학습함

3) loss function for RPN
<img src="https://user-images.githubusercontent.com/33839093/109640463-db9f6f00-7b93-11eb-80f4-8f528d499b4d.png" width="700">

> - Fast R-CNN과 동일하게 multi task loss를 사용함
> - i번째 anchor에 대해서 GT(ground truth)와 prediction값을 비교해 RPN의 class(물체가 있는지 없는지)와 box의 위치를 학습
> - L_cls : classification에는 log loss를 사용
> - L_reg : box regression에는 smooth L1 loss를 사용
> - GT label = 0이면 배경으로 간주하기 때문에, 뒷 항에 0이 곱해져 bbox reg이 학습되지 않음
> - balancing weight인 람다, N_cls, N_reg를 통해 두 항을 normalize함
> - bbox regression은 R-CNN과 동일한 식을 사용함
> <img src="https://user-images.githubusercontent.com/33839093/109640587-07225980-7b94-11eb-99a7-8704905a84f6.png" width="500">

### NMS(Non-Maximum Supression) & ROI Sampling
RPN단계에서 prediction된 box에 NMS와 ROI sampling을 거쳐 최종 ROI를 결정

- NMS
<img src="https://user-images.githubusercontent.com/33839093/109641324-ec9cb000-7b94-11eb-9296-d85f82d1ad4f.png" width="600">

> - 중복되는 bbox를 제거하기 위해 사용
> - 2번 단계에서 prediction한 box들을 ROI score로 정렬한 뒤, 높은 ROI score를 가진 박스와 겹친 박스를 지우는 방식
> - overlapping에 대한 threshold는 주로 0.6~0.9를 사용

- ROI sampling
> - 보통 training시에 NMS를 거치면 2000개의 ROI가 남음
> - **positive : negative 비율이 1:1이 되도록 ROI를 샘플링**
> - 256개를 샘플링하면, positive anchor 128개, negative anchor 128개가 샘플링됨
> - 만약 positive anchor가 128개가 안되면, zero padding을 하거나 IoU값이 가장 높은 박스를 positive로 사용함

### Faster R-CNN
> -  RPN을 통해 뽑은 ROI는 Fast R-CNN에서 selective search가 수행하던 일을 대신함
> - Loss에 RPN의 파라미터 값이 추가됨: cls_loss, box_reg_loss

### 성능 및 결론
<img src="https://user-images.githubusercontent.com/33839093/109642852-d42d9500-7b96-11eb-80f9-e8fc2bd96b90.png" width="600">

> - Fast R-CNN보다 속도, 성능이 모두 개선됨
> - Faster R-CNN의 속도는 7 fps로 실시간 object detection을 하기에는 적합하지 않음
> - ROI pooling에서 ROI가 stride에 항상 딱 떨어지지 않기 때문에 픽셀 손실이 있음
